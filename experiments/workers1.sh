# 64
python main.py --experiment-name "Workers_64" --env-id "FetchPushSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 64 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 1
python main.py --experiment-name "Workers_64" --env-id "FetchPushSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 64 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 621
python main.py --experiment-name "Workers_64" --env-id "FetchPushSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 64 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 1537
python main.py --experiment-name "Workers_64" --env-id "FetchPushSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 64 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 2209
python main.py --experiment-name "Workers_64" --env-id "FetchPushSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 64 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 345

# 16
python main.py --experiment-name "Workers_16" --env-id "FetchPushSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 16 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 1
python main.py --experiment-name "Workers_16" --env-id "FetchPushSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 16 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 621
python main.py --experiment-name "Workers_16" --env-id "FetchPushSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 16 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 1537
python main.py --experiment-name "Workers_16" --env-id "FetchPushSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 16 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 2209
python main.py --experiment-name "Workers_16" --env-id "FetchPushSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 16 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 345
