# BASELINE
python main.py --experiment-name "ReachBaseline" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 1
python main.py --experiment-name "ReachBaseline" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 621
python main.py --experiment-name "ReachBaseline" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 1537
python main.py --experiment-name "ReachBaseline" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 2209
python main.py --experiment-name "ReachBaseline" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --seed 345

# INTRINSIC MOTIVATION
python main.py --experiment-name "ReachIntrinsic" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --seed 1
python main.py --experiment-name "ReachIntrinsic" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --seed 621
python main.py --experiment-name "ReachIntrinsic" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --seed 1537
python main.py --experiment-name "ReachIntrinsic" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --seed 2209
python main.py --experiment-name "ReachIntrinsic" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --seed 345


# PREDICT DELTA STATE
python main.py --experiment-name "ReachDeltaObs" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --predict-delta-obs --seed 1
python main.py --experiment-name "ReachDeltaObs" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --predict-delta-obs --seed 621
python main.py --experiment-name "ReachDeltaObs" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --predict-delta-obs --seed 1537
python main.py --experiment-name "ReachDeltaObs" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --predict-delta-obs --seed 2209
python main.py --experiment-name "ReachDeltaObs" --env-id "FetchReachSparse-v3" --use-gae --gamma 0.95 --hidden-size 128 --entropy-coef 0.01 --num-processes 32 --num-steps 2048 --num-env-steps 30000000 --use-tensorboard --debug --pi-lr 1e-4 --v-lr 1e-3 --dyn-lr 1e-4 --grad-norm-max 5. --add-intrinsic-reward --intrinsic-coef 1 --max-intrinsic-reward 1.0 --predict-delta-obs --seed 345
